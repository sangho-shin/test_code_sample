{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800773f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from algorithms import aimodel\n",
    "from algorithms.logseq.log2template import Log2Template\n",
    "from common import constants\n",
    "from common.timelogger import TimeLogger\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd9f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSeq(aimodel.AIModel):\n",
    "    def __init__(self, config, logger):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "\n",
    "        self.params_logseq = None\n",
    "        self.window_size = self.params_logseq['window_size'] if self.params_logseq is not None else 30\n",
    "\n",
    "        # self.test_perc = self.config['parameter']['train']['data_set']['test'] if 'data_set' in config['parameter']['train'].keys() else None\n",
    "        self.batch_size = self.params_logseq['batch_size'] if self.params_logseq is not None else 512\n",
    "        self.epochs = self.params_logseq['epochs'] if self.params_logseq is not None else 50\n",
    "        self.top_k = self.params_logseq['top_k'] if self.params_logseq is not None else 10\n",
    "        self.hidden_size = self.params_logseq['hidden_size'] if self.params_logseq is not None else 512\n",
    "\n",
    "        # self.test_perc = self.config['parameter']['train']['data_set']['test'] if 'data_set' in config['parameter']['train'].keys() else None\n",
    "        self.test_perc = 30\n",
    "\n",
    "        # template model\n",
    "        self.log2template = Log2Template(config, logger)\n",
    "\n",
    "        # tf model\n",
    "        self.model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c372b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def set_top_k(self, parameter):\n",
    "        update_val = parameter['parameter']['service'][constants.MODEL_S_LOGSEQ]['top_k']\n",
    "        self.logger.info(f\"[LogSeq] top_k changed : {self.top_k} => {update_val}\")\n",
    "        self.top_k = update_val\n",
    "\n",
    "    def get_model(self):\n",
    "        n_classes = self.log2template.n_templates\n",
    "\n",
    "        inp = Input(shape=(self.window_size,))\n",
    "        emb = Embedding(n_classes+1, self.hidden_size)(inp)\n",
    "        lstm = LSTM(self.hidden_size, return_sequences=True)(emb)\n",
    "        lstm = LSTM(self.hidden_size//2, return_sequences=True)(lstm)\n",
    "        lstm = LSTM(self.hidden_size//4)(lstm)\n",
    "        out = Dense(n_classes, activation='softmax')(lstm)\n",
    "        model = Model(inp, out)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.005), loss='categorical_crossentropy',\n",
    "                      metrics=[TopKCategoricalAccuracy(k, name=f\"top_{k}\") for k in [1, 3, 5, 10, 20]])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_sequence_data(self, data):\n",
    "        x_data, y_data = [], []\n",
    "        for i in range(len(data) - self.window_size):\n",
    "            x_data.append(data[i:i + self.window_size])\n",
    "            y_data.append(data[i + self.window_size] - 1)\n",
    "\n",
    "        x_data, y_data = np.array(x_data), to_categorical(y_data, num_classes=self.log2template.n_templates)\n",
    "        return x_data, y_data\n",
    "\n",
    "    def fit(self, log_df):\n",
    "        if not os.path.exists(os.path.join(self.config['model_dir'], f\"{constants.MODEL_S_LOGSEQ}\")):\n",
    "            os.makedirs(os.path.join(self.config['model_dir'], f\"{constants.MODEL_S_LOGSEQ}\"))\n",
    "        with TimeLogger(f\"[LogSeq] model training time :\", self.logger):\n",
    "            time_s = time.time()\n",
    "\n",
    "            tidxs = self.log2template.log2tidx(log_df, fitting=True)\n",
    "\n",
    "            x_data, y_data = self.get_sequence_data(tidxs)\n",
    "\n",
    "            x_train, x_test = train_test_split(x_data, test_size=self.test_perc / 100, shuffle=False)\n",
    "            y_train, y_test = train_test_split(y_data, test_size=self.test_perc / 100, shuffle=False)\n",
    "\n",
    "            # Model\n",
    "            self.logger.info(f\"[LogSeq] tf_model training start\")\n",
    "            self.model = self.get_model()\n",
    "            init_epoch = 0# 10\n",
    "            callbacks = [LoggerCallback(self.epochs, self.logger)]\n",
    "            # self.model.fit(x_train, y_train, batch_size=self.batch_size, epochs=init_epoch, validation_data=(x_test, y_test), callbacks=callbacks, verbose=0)\n",
    "\n",
    "            time_fit_s = time.time()\n",
    "            callbacks.append(EarlyStopping(min_delta=0.01, patience=5, restore_best_weights=True))\n",
    "            hist = self.model.fit(x_train, y_train, batch_size=self.batch_size, epochs=self.epochs, initial_epoch=init_epoch, validation_data=(x_test, y_test), callbacks=callbacks, verbose=0)\n",
    "            time_e = time.time()\n",
    "            self.logger.info(f\"[LogSeq] tf_model training end (elapsed = {time_e - time_fit_s:.3f}s)\")\n",
    "\n",
    "            # TODO - return template_clusters\n",
    "            train_result = {\"from_date\": self.config['date'][0], \"to_date\": self.config['date'][-1], \"accuracy\": hist.history['val_top_1'][-1],\n",
    "                            \"train_metrics\": {},\n",
    "                            'mined_period': self.log2template.mined_period, 'n_templates': self.log2template.n_templates,\n",
    "                            'templates': [c.get_template() for c in self.log2template.template_miner.drain.clusters],\n",
    "                            \"except_failure_date_list\": None, \"except_business_list\": None,\n",
    "                            \"business_list\": None, \"train_business_status\": None, \"train_mode\": -1, \"outlier_mode\": -1}\n",
    "\n",
    "            return train_result\n",
    "\n",
    "    def predict(self, serving_logs):\n",
    "        tidxs = self.log2template.log2tidx(serving_logs[60-self.window_size:])\n",
    "\n",
    "        x_data, y_data = self.get_sequence_data(tidxs)\n",
    "        preds = list(map(lambda x: list(enumerate(x)), self.model.predict(x_data, batch_size=512)))\n",
    "        preds = np.array(list(map(lambda p: sorted(p, key=lambda x: x[1], reverse=True), preds)))\n",
    "        preds = preds[:, :self.top_k, :]\n",
    "        '''\n",
    "        # format\n",
    "        (tidx_1, proba_1) => top1\n",
    "        (tidx_2, proba_2) => top2\n",
    "               ...\n",
    "        (tidx_k-1, proba_k-1)\n",
    "        (tidx_k, proba_k) => topk\n",
    "        '''\n",
    "\n",
    "        result = {}\n",
    "        for i in range(len(preds)):\n",
    "            is_anomaly = np.argmax(y_data[i]) not in preds[i][:, 0]\n",
    "            # expected_templates = self.log2template.tidx2template(preds[i][:, 0])\n",
    "            expected_tidxs = preds[i][:, 0] + 1\n",
    "            probas = preds[i][:, 1]\n",
    "            result[str(i)] = {'anomaly': is_anomaly,\n",
    "                              'real': serving_logs['msg'].iloc[60+i],\n",
    "                              'expected_tidxs': expected_tidxs,\n",
    "                              # 'expected_templates': expected_templates,\n",
    "                              'probabilities': probas}\n",
    "            self.logger.debug(f\"result_{i} = {result[str(i)]}\")\n",
    "        return result\n",
    "\n",
    "    def save(self, model_dir):\n",
    "        self.log2template.save(model_dir)\n",
    "\n",
    "        model_path = os.path.join(model_dir, f\"{constants.MODEL_S_LOGSEQ}/tf_model.h5\")\n",
    "        self.model.save(model_path)\n",
    "        self.logger.info(f\"[LogSeq] tf_model saved (3/4)\")\n",
    "\n",
    "        etc_path = os.path.join(model_dir, f\"{constants.MODEL_S_LOGSEQ}/etc_info.pkl\")\n",
    "        etc_info = {'top_k': self.top_k, 'mined_period': self.log2template.mined_period}\n",
    "        joblib.dump(etc_info, etc_path)\n",
    "        self.logger.info(f\"[LogSeq] etc_info saved (4/4)\")\n",
    "\n",
    "    def load(self, model_dir):\n",
    "        try:\n",
    "            self.log2template.load(model_dir)\n",
    "            self.logger.info(f\"[LogSeq] template model loaded\")\n",
    "\n",
    "            tf_model_path = os.path.join(model_dir, f\"{constants.MODEL_S_LOGSEQ}/tf_model.h5\")\n",
    "            self.model = load_model(tf_model_path)\n",
    "            self.logger.info(f\"[LogSeq] tf model loaded\")\n",
    "\n",
    "            etc_path = os.path.join(model_dir, f\"{constants.MODEL_S_LOGSEQ}/etc_info.pkl\")\n",
    "            etc_info = joblib.load(etc_path)\n",
    "            self.top_k = etc_info['top_k']\n",
    "            self.log2template.mined_period = etc_info['mined_period']\n",
    "\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.info(f\"[LogSeq] Error log while Load() : {e}\")\n",
    "            return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ae61826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class LoggerCallback(Callback):\n",
    "    def __init__(self, epochs, logger):\n",
    "        super().__init__()\n",
    "        self.logger = logger\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.logger.info(f\"[LogSeq] epoch={epoch + 1}/{self.epochs}\"\n",
    "                         f\", top_1=(train={logs['top_1']:.3f}/test={logs['val_top_1']:.3f})\"\n",
    "                         f\", top_3=({logs['top_3']:.3f}/{logs['val_top_3']:.3f})\"\n",
    "                         f\", top_5=({logs['top_5']:.3f}/{logs['val_top_5']:.3f})\"\n",
    "                         f\", top_10=({logs['top_10']:.3f}/{logs['val_top_10']:.3f})\"\n",
    "                         f\", top_20=({logs['top_20']:.3f}/{logs['val_top_20']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b9e968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "26117766",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()\n",
    "\n",
    "with open(\"./log_txt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "    for d in data:\n",
    "        a.append(eval(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "445cf9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:53.153 [org.spri] ():...</td>\n",
       "      <td>20220706115953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:53.153 [org.spri] ():...</td>\n",
       "      <td>20220706115953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:53.153 [org.spri] ():...</td>\n",
       "      <td>20220706115953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:53.152 [org.spri] ():...</td>\n",
       "      <td>20220706115953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:53.152 [org.spri] ():...</td>\n",
       "      <td>20220706115953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29313</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...</td>\n",
       "      <td>20220706115901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29314</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...</td>\n",
       "      <td>20220706115901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29315</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...</td>\n",
       "      <td>20220706115901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29316</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...</td>\n",
       "      <td>20220706115901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29317</th>\n",
       "      <td>DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...</td>\n",
       "      <td>20220706115901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     msg           _time\n",
       "0      DEBUG   2022-07-06 11:59:53.153 [org.spri] ():...  20220706115953\n",
       "1      DEBUG   2022-07-06 11:59:53.153 [org.spri] ():...  20220706115953\n",
       "2      DEBUG   2022-07-06 11:59:53.153 [org.spri] ():...  20220706115953\n",
       "3      DEBUG   2022-07-06 11:59:53.152 [org.spri] ():...  20220706115953\n",
       "4      DEBUG   2022-07-06 11:59:53.152 [org.spri] ():...  20220706115953\n",
       "...                                                  ...             ...\n",
       "29313  DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...  20220706115901\n",
       "29314  DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...  20220706115901\n",
       "29315  DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...  20220706115901\n",
       "29316  DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...  20220706115901\n",
       "29317  DEBUG   2022-07-06 11:59:01.737 [org.spri] ():...  20220706115901\n",
       "\n",
       "[29318 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0aab785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger():\n",
    "    def debug(self, msg):\n",
    "        print(msg)\n",
    "    def info(self, msg):\n",
    "        print(msg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97b4854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "209bc886",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22976\\367293539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlogseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22976\\325886617.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, logger)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# template model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2template\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLog2Template\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# tf model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\jupyter\\hand-on\\algo\\algorithms\\logseq\\log2template.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, logger)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_DRAIN3_CONFIG_DICT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mtemplate_miner_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_dir'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{constants.MODEL_S_LOGSEQ}/template_miner.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemplate_miner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTemplateMiner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFilePersistence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate_miner_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_parser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmined_period\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;31m#{'from': '', 'to': ''}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'model_dir'"
     ]
    }
   ],
   "source": [
    "config = dict()\n",
    "\n",
    "logseq = LogSeq(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627bbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
