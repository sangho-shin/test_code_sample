{
 "cells": [
  {
   "cell_type": "raw",
   "id": "76cee243",
   "metadata": {},
   "source": [
    "팬더스 라이브러리 - 균일한 타입의 데이터로 이뤄진 열을 입력으로 받아서 불균일한 타입의 표로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f50239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순 (1차원) 확산 의사 코드\n",
    "\n",
    "# 초기 조건을 생성한다.\n",
    "\n",
    "# ... 확산 방정식 부분 읽기만"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28af846e",
   "metadata": {},
   "source": [
    "\n",
    "메모리 할당을 줄여서 속도를 빠르게 하자\n",
    "ex) 매번 동일하게 할당되는 변수는 1번 할당 후 이미 할당된 공간을 재사용하는 쪽이 성능 향상에 도움이 된다.\n",
    "이렇게 해서 속도를 개선하더라도 그 변경이 코드 기반을 망치지 않고 정상적으로 동작하는지 항상 프로파일링 해야한다.\n",
    "\n",
    "리눅스 perf 명령어로 CPU를 얼마나 효율적으로 사용하는지 볼수 있음"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf035365",
   "metadata": {},
   "source": [
    "넘파이 입문\n",
    "\n",
    "효율적인 백터 연산을 제공\n",
    "데이터를 연속된 메모리 공간에 저장하며 이에 대한 백터 연산도 지원\n",
    "그결과 넘파이 배열에 대해서 수행하는 산술 연산은 개별 항목을 하나씩 순회하며 처리할 필요가 없다.\n",
    "이로 인해 행렬 연산이 간다해질 뿐만 아니라 계산도 빨라짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96128b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.8 ms ± 1.77 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "from array import array\n",
    "import numpy\n",
    "\n",
    "def norm_square_list(vector):\n",
    "    norm = 0\n",
    "    for v in vector:\n",
    "        norm += v * v\n",
    "    return norm\n",
    "    \n",
    "vector = list(range(1_000_000))\n",
    "%timeit norm_square_list(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fdefc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ms ± 61.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def norm_square_numpy(vector):\n",
    "    return numpy.sum(vector * vector)\n",
    "\n",
    "vector = numpy.arange(1_000_000)\n",
    "%timeit norm_square_numpy(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4796f500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541 µs ± 25.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def norm_square_numpy_dot(vector):\n",
    "    return numpy.dot(vector, vector)\n",
    "\n",
    "vector = numpy.arange(1_000_000)\n",
    "%timeit norm_square_numpy_dot(vector)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f7dd6ab",
   "metadata": {},
   "source": [
    "내부적으로 넘파이는 잘 최적화된 C 코드를 통해 CPU에서 지원하는 백터화 기능의 장점을 활용한다.\n",
    "산술 계산에 특히 중요한 역할을 함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bac285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4.1 메모리 할당과 제자리 연산\n",
    "# 제자리 연산이란.. +=, *= 처럼 입력 중 하나가 위치한 메모리에 결괏값을 다시 저장하는 연산\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198cc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.random.random((10,10))\n",
    "array2 = np.random.random((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0992ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2711724358896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d54f5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2711724358512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa11b276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2711724358896"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 += array2\n",
    "id(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb42b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2711724770960"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = array1 + array2\n",
    "id(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe22db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제자리 연산을 사용하지 않으면 예상한 대로 실행 속도가 느려짐을 확인할수 있다.\n",
    "# 배열이 크기가 커질수록 메모리 할당에 시간이 더 오래 걸리므로 이 차이는 더 벌이진다.\n",
    "# 하지만 이 효과는 배열 크기가 CPU 캐시보다 큰 경우에만 발생한다는 점을 알아둬야한다.\n",
    "# 배열이 더 작아서 입력과 출력이 모두 캐시에 들어갈 수 있다면 백터화의 이점을 누릴 수 있으므로 제자리 연산이 아닌 쪽이 더 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fda73a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.91 ms ± 42.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit array1, array2 = np.random.random((2, 1000, 1000))\n",
    "array1 = array1 + array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96cf64fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766 µs ± 27.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit array1, array2 = np.random.random((2, 1000, 1000))\n",
    "array1 += array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76cd74a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 µs ± 147 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit array1, array2 = np.random.random((2, 50, 50))\n",
    "array1 = array1 + array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67b3f107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954 ns ± 14.4 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit array1, array2 = np.random.random((2, 50, 50))\n",
    "array1 += array2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60de3845",
   "metadata": {},
   "source": [
    "6.8 판다스\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d71a23d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mols_sklearn\u001b[39m(row):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124;03m\"\"\"Solve OLS using scikit-learn's LinearRegression\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def ols_sklearn(row):\n",
    "    \"\"\"Solve OLS using scikit-learn's LinearRegression\"\"\"\n",
    "    est = LinearRegression() \n",
    "    X = np.arange(row.shape[0]).reshape(-1, 1) # shape (14, 1)\n",
    "    # note that the intercept is built inside LinearRegression\n",
    "    est.fit(X, row.values) \n",
    "    m = est.coef_[0] # note c is in est.intercept_\n",
    "    return m\n",
    "\n",
    "def ols_lstsq(row):\n",
    "    \"\"\"Solve OLS using numpy.linalg.lstsq\"\"\"\n",
    "    # build X values for [0, 13]\n",
    "    X = np.arange(row.shape[0]) # shape (14,)\n",
    "    ones = np.ones(row.shape[0]) # constant used to build intercept\n",
    "    A = np.vstack((X, ones)).T # shape(14, 2)\n",
    "    # lstsq returns the coefficient and intercept as the first result \n",
    "    # followed by the residuals and other items\n",
    "    m, c = np.linalg.lstsq(A, row.values, rcond=-1)[0] \n",
    "    return m\n",
    "\n",
    "def ols_lstsq_raw(row):\n",
    "    \"\"\"Variant of `ols_lstsq` where row is a numpy array (not a Series)\"\"\"\n",
    "    X = np.arange(row.shape[0])\n",
    "    ones = np.ones(row.shape[0])\n",
    "    A = np.vstack((X, ones)).T\n",
    "    m, c = np.linalg.lstsq(A, row, rcond=-1)[0] \n",
    "    return m"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e56980ea",
   "metadata": {},
   "source": [
    "pandas에서 for loop나 df.iterrows 같은 구문은 오버헤드를 피할수 없다.\n",
    "\n",
    "apply를 사용해 전형적인 판다스 함수로 적용하자\n",
    "\n",
    "일반적으로 판다스에서는 concat(넘파이에서는 concatenate)를 반복 호출하는 일은 피해야 한다.\n",
    "새로운 Series객체가 새로운 메모리 위치에 생긴다.\n",
    "중간 결과를 모을때는 직접 기존 Series나 DataFrame객체에 새 값을 추가하는 대신,\n",
    "리스트를 만든 다음 이 리스트에서 Series나 DataFrame을 구성할 것을 강력히 권장한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b8420dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m      6\u001b[0m     row \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[row_idx]\n\u001b[0;32m      7\u001b[0m     m \u001b[38;5;241m=\u001b[39m ols_lstsq(row)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 나쁜코드\n",
    "import pandas as pd \n",
    "\n",
    "results = None\n",
    "for row_idx in range(df.shape[0]):\n",
    "    row = df.iloc[row_idx]\n",
    "    m = ols_lstsq(row)\n",
    "    \n",
    "    if results is None:\n",
    "        results = pd.Series([m])\n",
    "    else:\n",
    "        results = pd.concat((results, pd.Series([m])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50b68086",
   "metadata": {},
   "source": [
    "# pandas apply를 이용한 접근 방법의 추가 이점은 연산을 병렬화 할수 있다는점과\n",
    "# 생성한 함수가 수행하는 연산이 맞는지 확인하는 단위 테스트를 간결하게 작성할 수 있다는 점이다.\n",
    "# 간결한 단위 테스트가 있으면 가독성과 유지보수성이 높아진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20c1a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bottleneck\n",
    "import numexpr"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f42099ac",
   "metadata": {},
   "source": [
    "pandas는 메서드 체이닝 스타일을 지원하지만 너무 많은 행을 체이닝하는것은 바람직하지 않음 (디버깅 어려움)\n",
    "\n",
    "처리를 필요 이상으로 하지 말라.\n",
    "\n",
    "계산하기 전에 데이터에 필터를 적용하자\n",
    "\n",
    "필요없는 열은 drop를 사용해 제거해서 메모리 사용과 데이터 팽창을 막아라\n",
    "\n",
    "카디널리티가 작은 문자열 (예를 들어 yes/no, 타입1/타입2/타입3)이 있는 큰 Series는 category 타입으로 변환해보라\n",
    "이렇게하면 value_counts와 groupby같은 연산이 더 빨리 작동하고 Series도 RAM를 더 적게 사용한다.\n",
    "\n",
    "dtype를 더 작은 범위의 값이 필요하면 범위를 줄여서 RAM 사용량을 더 줄일수 있다.\n",
    "\n",
    "DataFrame을 진화시키고 새로운 복사본을 만드는 과정에서 del 키워드를 사용하면 예전의 참조를 삭제하고 메모리에서 해제할 수 있다는 사실을 기억하라.\n",
    "\n",
    "처리할 데이터를 준비하는 과정에서 큰 DataFrame을 조작한다면, 해당 연산을 함수나 별도의 스크립트로 분리한다음 to_pickle을 사용해 결과를 언제든 불러올 수 있게 준비된 상태로 디스크에 영속화할 수 있다. 이렇게 저장하고 나면 매번 처리를 거치지 않아도 DataFrame을 준비해 그 이후 작업을 수행할 수 있다.\n",
    "\n",
    "inplace=True 연산자를 피하라. in-place연산은 점차 라이브러리 삭제될 예정이다.\n",
    "\n",
    "pandas를 더 빠르게 만드는 기존 도구로는 Modin과 GPU에 초점을 맞춘 cuDF, Vaex 라이브러리(pandas와 비슷한 인터페이스를 유지하면서 지연계산을 활용해 RAM 크기를 벗어나느 아주 큰 데이터셋을 처리하도록 설계됐다,)\n",
    "Vaex는 큰 데이터셋과 문자열을 많이 처리하는 연산에 특화됐다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analyzer",
   "language": "python",
   "name": "data_analyzer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
